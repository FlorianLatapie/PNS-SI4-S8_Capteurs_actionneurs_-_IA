{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vinh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import wave\n",
    "from pathlib import Path\n",
    "from os import path, makedirs\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Conv1D, AvgPool1D, MaxPool1D, ZeroPadding1D, BatchNormalization, Flatten, Dense, Activation\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from mutagen.wave import WAVE\n",
    "from mutagen.mp3 import MP3\n",
    "from pydub import AudioSegment\n",
    "from random import choice"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-22T15:42:39.429853Z",
     "end_time": "2023-04-22T15:42:48.230398Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Récupération des données"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Traitement des données"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# A modifier\n",
    "def split_sounds(sound_data):\n",
    "    curr_path = sound_data[\"curr_path\"]\n",
    "    absolute_path = path.dirname(__file__)\n",
    "    dest_dirname = sound_data['dest_dirname']\n",
    "    dest_filename, extension = path.splitext(sound_data['dest_filename'])\n",
    "    audio_length = int(WAVE(curr_path).info.length)\n",
    "    audio = AudioSegment.from_wav(curr_path)\n",
    "\n",
    "    relative_path = f\"{DEST_DIR}/testing_list.txt\"\n",
    "    absolute_path = path.dirname(__file__)\n",
    "    testing_file_path = path.join(absolute_path, relative_path)\n",
    "\n",
    "    with open(testing_file_path,\"a+\") as file:\n",
    "        for i in range(audio_length):\n",
    "            t1 = i * 1000\n",
    "            t2 = t1 + 1000\n",
    "            cut_audio = audio[t1:t2]\n",
    "            relative_path = f\"{DEST_DIR}/{dest_dirname}/{dest_filename}_{i}{extension}\"\n",
    "            dest_path = path.join(absolute_path, relative_path)\n",
    "            makedirs(path.dirname(dest_path), exist_ok=True)\n",
    "            cut_audio.export(dest_path, format=\"wav\")\n",
    "            if choice([True, False, False]):\n",
    "                file.write(f'{dest_dirname}/{dest_filename}_{i}{extension}\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Création des jeux de données"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_dir = Path('recordings')\n",
    "\n",
    "CLASSES = [\"Parus major\", \"Turdus merula\", \"Fringilla-coelebs\"]\n",
    "\n",
    "with (dataset_dir/ 'testing_list.txt').open() as f:\n",
    "    testing_list = f.read().splitlines()\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for recording in dataset_dir.glob('**/*.wav'):\n",
    "    if not recording.parent.name in CLASSES:\n",
    "        continue\n",
    "    label = CLASSES.index(recording.parent.name)\n",
    "\n",
    "    with wave.open(str(recording)) as f :\n",
    "        data = np.frombuffer(f.readframes(f.getnframes()), dtype=np.int16).copy()\n",
    "\n",
    "    data = data.astype(np.float32)\n",
    "    data.resize((16000, 1))\n",
    "\n",
    "    if str(recording.relative_to(dataset_dir)) in testing_list:\n",
    "        x_test.append(data)\n",
    "        y_test.append(label)\n",
    "    else:\n",
    "        x_train.append(data)\n",
    "        y_train.append(label)\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = to_categorical(np.array(y_train))\n",
    "x_test = np.array(x_test)\n",
    "y_test = to_categorical(np.array(y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Normalize data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_mean = x_train.mean()\n",
    "x_std = x_train.std()\n",
    "\n",
    "x_train -= x_mean\n",
    "x_test -= x_mean\n",
    "x_train /= x_std\n",
    "x_test /= x_std"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exporter les données"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.savetxt('x_test.csv', x_test.reshape(x_test.shape[0], -1), delimiter=',', fmt='%s')\n",
    "np.savetxt('y_test.csv', y_test, delimiter=',', fmt='%s')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build model M5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifier\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(16000, 1)))\n",
    "model.add(Conv1D(filters=128, kernel_size=80, strides=4, activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=4, strides=1, padding='valid'))\n",
    "model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=4, strides=1, padding='valid'))\n",
    "model.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=4, strides=1, padding='valid'))\n",
    "model.add(Conv1D(filters=512, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=4, strides=1, padding='valid'))\n",
    "model.add(AvgPool1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=10))\n",
    "model.add(Activation('softmax'))  # SoftMax activation needs to be separate from Dense to remove it later on\n",
    "# EXPLORE Learning Rate\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=10e-3)\n",
    "model.summary()\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=5, batch_size=10, validation_data=(x_test, y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate model on test dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test, verbose=2)\n",
    "pred_test = model.predict(x_test)\n",
    "print(tf.math.confusion_matrix(y_test.argmax(axis=1), pred_test.argmax(axis=1)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate model on small dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test, verbose=2)\n",
    "pred_test_250 = model.predict(x_test)\n",
    "print(tf.math.confusion_matrix(y_test.argmax(axis=1), pred_test_250.argmax(axis=1)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save trained model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save('lab_gsc.h5')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Remove SoftMax layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = tf.keras.Model(model.input, model.layers[-2].output, name=model.name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Install MicroAI for C inference code generation (kerascnn2c module)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install https://bitbucket.org/edge-team-leat/microai_public/get/6adfbcb347d3.zip#subdirectory=third_party/kerascnn2c_fixed\n",
    "import kerascnn2c"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate C code for the trained model with 16-bit fixed-point representation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "res = kerascnn2c.Converter(output_path=Path('gsc_output_fixed'),\n",
    "                           fixed_point=9, # Number of bits for the fractional part, Q7.9 format\n",
    "                           number_type='int16_t', # Data type for weights/activations (16 bits quantization)\n",
    "                           long_number_type='int32_t', # Data type for intermediate results\n",
    "                           number_min=-(2**15), # Minimum value for 16-bit signed integers\n",
    "                           number_max=(2**15)-1 # Maximum value for 16-bit signed integers\n",
    "                          ).convert_model(copy.deepcopy(model))\n",
    "with open('gsc_model_fixed.h', 'w') as f:\n",
    "    f.write(res)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compile the 16-bit fixed-point C code for x86 and evaluate on small dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!g++ -Wall -Wextra -pedantic -Ofast -o gsc_fixed -Igsc_output_fixed/ gsc_output_fixed/model.c main.cpp\n",
    "!./gsc_fixed x_test_gsc_250.csv y_test_gsc_250.csv"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
