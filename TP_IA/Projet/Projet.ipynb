{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import copy\n",
    "import wave\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Conv1D, AvgPool1D, MaxPool1D, ZeroPadding1D, BatchNormalization, Flatten, Dense, Activation\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import os\n",
    "from download_dataset import get_bird_json, download_from_bird_json_infos\n",
    "from prepare_and_clean_dataset import split_audio_file\n",
    "import librosa"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T23:26:20.960063Z",
     "end_time": "2023-04-23T23:26:42.592305Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Récupération des données"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting recordings data for Parus+major with quality A\n",
      "Getting recordings data for Parus+major with quality B\n",
      "Getting recordings data for Parus+major with quality C\n",
      "Downloading file: 1 out of 10 ( XC795227-d)charbo.mp3 )\n",
      "Downloading file: 2 out of 10 ( XC795108-230404_11Parus-major-song-10.30-Camiño-galegas,-Biobra,-Rubiá.mp3 )\n",
      "Downloading file: 3 out of 10 ( XC794967-230403_41-Parus-major-14.30-Covas,-Rubiá.mp3 )\n",
      "Downloading file: 4 out of 10 ( XC794645-MVI_5842.mp3 )\n",
      "Downloading file: 5 out of 10 ( XC793834-pmajor_230415_aluvium.wav )\n",
      "Downloading file: 6 out of 10 ( XC793240-230413_1596-1739-Kohlmeise.-CZ,-Becov-nad-Teplou.-Stephan-Risch.wav )\n",
      "Downloading file: 7 out of 10 ( XC793160-Kohlmeise--Würmseeplatz--München.mp3 )\n",
      "Downloading file: 8 out of 10 ( XC793158-Kohlmeise--Ambacher-Straße--München.mp3 )\n",
      "Downloading file: 9 out of 10 ( XC792834-Tit,-Great-(Nové-Mlyny)-19.4.22-SF.mp3 )\n",
      "Downloading file: 10 out of 10 ( XC792650-20230411_171921-cinciallegra.mp3 )\n",
      "Getting recordings data for Turdus+merula with quality A\n",
      "Getting recordings data for Turdus+merula with quality B\n",
      "Getting recordings data for Turdus+merula with quality C\n",
      "Downloading file: 1 out of 10 ( XC794897-Turdus-merula_song-male_200423_Escober-de-Tabara.wav )\n",
      "Downloading file: 2 out of 10 ( XC794896-Common-Blackbird-1.mp3 )\n",
      "Downloading file: 3 out of 10 ( XC794865-blackbird.wav )\n",
      "Downloading file: 4 out of 10 ( XC794533-blackbird.wav )\n",
      "Downloading file: 5 out of 10 ( XC794140-merelzang.wav )\n",
      "Downloading file: 6 out of 10 ( XC794025-TurmerTop2_Jardim-Botânico-de-Pedro-Miguel.wav )\n",
      "Downloading file: 7 out of 10 ( XC794024-TurmerTop1_Jardim-Botânico-de-Pedro-Miguel.wav )\n",
      "Downloading file: 8 out of 10 ( XC793995-Turdus-merula_2023.04.14_19.54_01.mp3 )\n",
      "Downloading file: 9 out of 10 ( XC793975-20230316_150905-merlo-Bertignano-.mp3 )\n",
      "Downloading file: 10 out of 10 ( XC793974-20230417_133913-merlo-palazzi-masseria.mp3 )\n",
      "Getting recordings data for Fringilla+coelebs with quality A\n",
      "Getting recordings data for Fringilla+coelebs with quality B\n",
      "Getting recordings data for Fringilla+coelebs with quality C\n",
      "Downloading file: 1 out of 10 ( XC795208-20230422_093540-zięba-eBird-do-xc.wav )\n",
      "Downloading file: 2 out of 10 ( XC795040-230404_26PImpín-call-and-song---10.00-AS-galegas,-Biobra.mp3 )\n",
      "Downloading file: 3 out of 10 ( XC795039-230404_22-Pimpín-pink-call-and-song-9.30-As-galegas,-Biobra,-Rubiá.mp3 )\n",
      "Downloading file: 4 out of 10 ( XC795038-230404_22-Pimpín-pink-call-and-song-9.30-As-galegas,-Biobra,-Rubiá.mp3 )\n",
      "Downloading file: 5 out of 10 ( XC795035-230404_02Pimpín-bo-callandsong-9.00-Biobra,-Rubiá.mp3 )\n",
      "Downloading file: 6 out of 10 ( XC794236-pinson.mp3 )\n",
      "Downloading file: 7 out of 10 ( XC794200-FricoeTop2_Santo-António.wav )\n",
      "Downloading file: 8 out of 10 ( XC794199-Fricoetop1_Santo-António.wav )\n",
      "Downloading file: 9 out of 10 ( XC794184-Fringilla-coelebstopinho1_Poços.wav )\n",
      "Downloading file: 10 out of 10 ( XC794183-Fringilla-coelebsTop1_Poços.wav )\n",
      "splitting audio into multiple recordings\n",
      "looking into folder: recordings\\Fringilla_coelebs\n",
      "splitting recording 1 A_XC794183-Fringilla-coelebsTop1_Poços.wav out of 10 for bird Fringilla_coelebs\n",
      "splitting recording 2 A_XC794184-Fringilla-coelebstopinho1_Poços.wav out of 10 for bird Fringilla_coelebs\n",
      "splitting recording 3 A_XC794199-Fricoetop1_Santo-António.wav out of 10 for bird Fringilla_coelebs\n",
      "splitting recording 4 A_XC794200-FricoeTop2_Santo-António.wav out of 10 for bird Fringilla_coelebs\n",
      "splitting recording 5 A_XC794236-pinson.mp3 out of 10 for bird Fringilla_coelebs\n",
      "splitting recording 6 A_XC795035-230404_02Pimpín-bo-callandsong-9.00-Biobra,-Rubiá.mp3 out of 10 for bird Fringilla_coelebs\n",
      "splitting recording 7 A_XC795038-230404_22-Pimpín-pink-call-and-song-9.30-As-galegas,-Biobra,-Rubiá.mp3 out of 10 for bird Fringilla_coelebs\n",
      "splitting recording 8 A_XC795039-230404_22-Pimpín-pink-call-and-song-9.30-As-galegas,-Biobra,-Rubiá.mp3 out of 10 for bird Fringilla_coelebs\n",
      "splitting recording 9 A_XC795040-230404_26PImpín-call-and-song---10.00-AS-galegas,-Biobra.mp3 out of 10 for bird Fringilla_coelebs\n",
      "splitting recording 10 A_XC795208-20230422_093540-zięba-eBird-do-xc.wav out of 10 for bird Fringilla_coelebs\n",
      "looking into folder: recordings\\Parus_major\n",
      "splitting recording 1 A_XC792650-20230411_171921-cinciallegra.mp3 out of 10 for bird Parus_major\n",
      "splitting recording 2 A_XC792834-Tit,-Great-(Nové-Mlyny)-19.4.22-SF.mp3 out of 10 for bird Parus_major\n",
      "splitting recording 3 A_XC793158-Kohlmeise--Ambacher-Straße--München.mp3 out of 10 for bird Parus_major\n",
      "splitting recording 4 A_XC793160-Kohlmeise--Würmseeplatz--München.mp3 out of 10 for bird Parus_major\n",
      "splitting recording 5 A_XC793240-230413_1596-1739-Kohlmeise.-CZ,-Becov-nad-Teplou.-Stephan-Risch.wav out of 10 for bird Parus_major\n",
      "splitting recording 6 A_XC793834-pmajor_230415_aluvium.wav out of 10 for bird Parus_major\n",
      "splitting recording 7 A_XC794645-MVI_5842.mp3 out of 10 for bird Parus_major\n",
      "splitting recording 8 A_XC794967-230403_41-Parus-major-14.30-Covas,-Rubiá.mp3 out of 10 for bird Parus_major\n",
      "splitting recording 9 A_XC795108-230404_11Parus-major-song-10.30-Camiño-galegas,-Biobra,-Rubiá.mp3 out of 10 for bird Parus_major\n",
      "splitting recording 10 A_XC795227-d)charbo.mp3 out of 10 for bird Parus_major\n",
      "looking into folder: recordings\\Turdus_merula\n",
      "splitting recording 1 A_XC793974-20230417_133913-merlo-palazzi-masseria.mp3 out of 10 for bird Turdus_merula\n",
      "splitting recording 2 A_XC793975-20230316_150905-merlo-Bertignano-.mp3 out of 10 for bird Turdus_merula\n",
      "splitting recording 3 A_XC793995-Turdus-merula_2023.04.14_19.54_01.mp3 out of 10 for bird Turdus_merula\n",
      "splitting recording 4 A_XC794024-TurmerTop1_Jardim-Botânico-de-Pedro-Miguel.wav out of 10 for bird Turdus_merula\n",
      "splitting recording 5 A_XC794025-TurmerTop2_Jardim-Botânico-de-Pedro-Miguel.wav out of 10 for bird Turdus_merula\n",
      "splitting recording 6 A_XC794140-merelzang.wav out of 10 for bird Turdus_merula\n",
      "splitting recording 7 A_XC794533-blackbird.wav out of 10 for bird Turdus_merula\n",
      "splitting recording 8 A_XC794865-blackbird.wav out of 10 for bird Turdus_merula\n",
      "splitting recording 9 A_XC794896-Common-Blackbird-1.mp3 out of 10 for bird Turdus_merula\n",
      "splitting recording 10 A_XC794897-Turdus-merula_song-male_200423_Escober-de-Tabara.wav out of 10 for bird Turdus_merula\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "main_bird = \"Parus major\"\n",
    "main_bird_quality = (\"A\", \"B\", \"C\")\n",
    "number_of_main_bird_recordings = 10\n",
    "\n",
    "test_bird_1 = \"Turdus merula\"\n",
    "test_bird_1_quality = (\"A\", \"B\", \"C\")\n",
    "number_of_test_bird_1_recordings = 10\n",
    "\n",
    "test_bird_2 = \"Fringilla coelebs\"\n",
    "test_bird_2_quality = (\"A\", \"B\", \"C\")\n",
    "number_of_test_bird_2_recordings = 10\n",
    "\n",
    "recordings_folder = \"recordings\"\n",
    "\n",
    "# dl data\n",
    "main_bird_recordings_json = get_bird_json(main_bird, main_bird_quality, number_of_main_bird_recordings)\n",
    "download_from_bird_json_infos(recordings_folder, main_bird_recordings_json)\n",
    "\n",
    "test_bird_1_recordings_json = get_bird_json(test_bird_1, test_bird_1_quality, number_of_test_bird_1_recordings)\n",
    "download_from_bird_json_infos(recordings_folder, test_bird_1_recordings_json)\n",
    "\n",
    "test_bird_2_recordings_json = get_bird_json(test_bird_2, test_bird_2_quality, number_of_test_bird_2_recordings)\n",
    "download_from_bird_json_infos(recordings_folder, test_bird_2_recordings_json)\n",
    "\n",
    "# clean data\n",
    "\n",
    "print(\"splitting audio into multiple recordings\")\n",
    "for bird_type in os.listdir(recordings_folder):\n",
    "    bird_folder = os.path.join(recordings_folder, bird_type)\n",
    "    print(\"looking into folder:\", bird_folder)\n",
    "    if os.path.isdir(bird_folder):\n",
    "        number_of_recordings = len(os.listdir(bird_folder))\n",
    "        for index, recording in enumerate(os.listdir(bird_folder)):\n",
    "            print(\"splitting recording\", str(index+1), recording, \"out of\", number_of_recordings, \"for bird\", bird_type)\n",
    "            recording_path = os.path.join(bird_folder, recording)\n",
    "            split_audio_file(recording_path, bird_folder, recording.split(\".\")[0], 3)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T23:27:35.702472Z",
     "end_time": "2023-04-23T23:30:11.154082Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Création des jeux de données"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# create train, test and text pointers\n",
    "recordings_folder = \"recordings\"\n",
    "main_bird = \"Parus major\"\n",
    "\n",
    "file_name = \"testing_list.txt\"\n",
    "\n",
    "count = 0\n",
    "with open(os.path.join(recordings_folder, file_name), \"w\", encoding=\"utf-8\") as f:\n",
    "    for bird_type in os.listdir(recordings_folder):\n",
    "        bird_folder = os.path.join(recordings_folder, bird_type)\n",
    "        if os.path.isdir(bird_folder):\n",
    "            for recording in os.listdir(bird_folder):\n",
    "                sound_filename = os.path.join(bird_folder, recording)\n",
    "                if os.path.isfile(sound_filename) and \"splitted_\" in sound_filename:\n",
    "                    if count < 1200:\n",
    "                        if np.random.rand() > 0.3:\n",
    "                            f.write(sound_filename + \"\\n\")\n",
    "                            count += 1\n",
    "            count = 0\n",
    "print(\"Done\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T23:30:59.117997Z",
     "end_time": "2023-04-23T23:30:59.218319Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Création des jeux de données"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "dataset_dir = Path('recordings')\n",
    "\n",
    "CLASSES = [\"Parus_major\", \"Turdus_merula\", \"Fringilla_coelebs\"]\n",
    "\n",
    "with (dataset_dir/ 'testing_list.txt').open(encoding='utf-8') as f:\n",
    "    testing_list = f.read().splitlines()\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for recording in dataset_dir.glob('**/*.wav'):\n",
    "    if not recording.parent.name in CLASSES:\n",
    "        continue\n",
    "    if \"splitted_\" not in str(recording):\n",
    "        continue\n",
    "    label = CLASSES.index(recording.parent.name)\n",
    "\n",
    "    with wave.open(str(recording)) as f :\n",
    "        data = np.frombuffer(f.readframes(f.getnframes()), dtype=np.int16).copy()\n",
    "\n",
    "    data = data.astype(np.float32)\n",
    "    data.resize((16000, 1))\n",
    "\n",
    "    if \"splitted_\" in str(recording):\n",
    "        if str(recording) in testing_list:\n",
    "            x_test.append(data)\n",
    "            y_test.append(label)\n",
    "        else:\n",
    "            x_train.append(data)\n",
    "            y_train.append(label)\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = to_categorical(np.array(y_train))\n",
    "x_test = np.array(x_test)\n",
    "y_test = to_categorical(np.array(y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T19:27:59.930822Z",
     "end_time": "2023-04-23T19:28:03.817030Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Normalize data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "x_mean = x_train.mean()\n",
    "x_std = x_train.std()\n",
    "\n",
    "x_train -= x_mean\n",
    "x_test -= x_mean\n",
    "x_train /= x_std\n",
    "x_test /= x_std"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T19:28:03.819034Z",
     "end_time": "2023-04-23T19:28:04.192321Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exporter les données"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "np.savetxt('x_test.csv', x_test.reshape(x_test.shape[0], -1), delimiter=',', fmt='%s')\n",
    "np.savetxt('y_test.csv', y_test, delimiter=',', fmt='%s')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T19:30:25.915232Z",
     "end_time": "2023-04-23T19:30:54.752852Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build model M5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-23T19:37:52.462144Z",
     "end_time": "2023-04-23T19:37:52.607145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_36 (Conv1D)          (None, 3981, 128)         10368     \n",
      "                                                                 \n",
      " max_pooling1d_38 (MaxPoolin  (None, 3978, 128)        0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_37 (Conv1D)          (None, 3976, 128)         49280     \n",
      "                                                                 \n",
      " max_pooling1d_39 (MaxPoolin  (None, 3973, 128)        0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_38 (Conv1D)          (None, 3971, 256)         98560     \n",
      "                                                                 \n",
      " max_pooling1d_40 (MaxPoolin  (None, 3968, 256)        0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_39 (Conv1D)          (None, 3966, 512)         393728    \n",
      "                                                                 \n",
      " max_pooling1d_41 (MaxPoolin  (None, 3963, 512)        0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " average_pooling1d_11 (Avera  (None, 1981, 512)        0         \n",
      " gePooling1D)                                                    \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 1014272)           0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 3)                 3042819   \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 3)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,594,755\n",
      "Trainable params: 3,594,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Modifier\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(16000, 1)))\n",
    "# model.add(MaxPool1D(pool_size=4, strides=3, padding='valid'))\n",
    "# model.add(Conv1D(filters=128, kernel_size=80, activation='relu'))\n",
    "# model.add(MaxPool1D(pool_size=4, strides=3, padding='valid'))\n",
    "# model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "# model.add(MaxPool1D(pool_size=4, strides=3, padding='valid'))\n",
    "# model.add(Conv1D(filters=32, kernel_size=7, activation='relu'))\n",
    "# model.add(MaxPool1D(pool_size=4, strides=3, padding='valid'))\n",
    "# model.add(AvgPool1D())\n",
    "model.add(Conv1D(filters=128, kernel_size=80, strides=4, activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=4, strides=1, padding='valid'))\n",
    "model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=4, strides=1, padding='valid'))\n",
    "model.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=4, strides=1, padding='valid'))\n",
    "model.add(Conv1D(filters=512, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=4, strides=1, padding='valid'))\n",
    "model.add(AvgPool1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=3))\n",
    "model.add(Activation('softmax'))  # SoftMax activation needs to be separate from Dense to remove it later on\n",
    "# EXPLORE Learning Rate\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=10e-3)\n",
    "model.summary()\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "574/574 [==============================] - 519s 902ms/step - loss: 1.1169 - categorical_accuracy: 0.7822 - val_loss: 1.5277 - val_categorical_accuracy: 0.3333\n",
      "Epoch 2/5\n",
      "574/574 [==============================] - 528s 919ms/step - loss: 0.6694 - categorical_accuracy: 0.7843 - val_loss: 1.6034 - val_categorical_accuracy: 0.3333\n",
      "Epoch 3/5\n",
      "574/574 [==============================] - 528s 921ms/step - loss: 0.6692 - categorical_accuracy: 0.7843 - val_loss: 1.5230 - val_categorical_accuracy: 0.3333\n",
      "Epoch 4/5\n",
      "574/574 [==============================] - 572s 997ms/step - loss: 0.6700 - categorical_accuracy: 0.7843 - val_loss: 1.5895 - val_categorical_accuracy: 0.3333\n",
      "Epoch 5/5\n",
      "574/574 [==============================] - 540s 941ms/step - loss: 0.6694 - categorical_accuracy: 0.7843 - val_loss: 1.5546 - val_categorical_accuracy: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x134a2b480d0>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5, batch_size=10, validation_data=(x_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T19:37:54.838455Z",
     "end_time": "2023-04-23T20:22:41.998242Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate model on test dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 75s - loss: 1.5546 - categorical_accuracy: 0.3333 - 75s/epoch - 662ms/step\n",
      "113/113 [==============================] - 74s 655ms/step\n",
      "tf.Tensor(\n",
      "[[   0 1200    0]\n",
      " [   0 1200    0]\n",
      " [   0 1200    0]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=2)\n",
    "pred_test = model.predict(x_test)\n",
    "print(tf.math.confusion_matrix(y_test.argmax(axis=1), pred_test.argmax(axis=1)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T20:22:41.978246Z",
     "end_time": "2023-04-23T20:25:10.984075Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save trained model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "model.save('lab_gsc.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T18:22:24.073492Z",
     "end_time": "2023-04-23T18:22:24.267154Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Remove SoftMax layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "model = tf.keras.Model(model.input, model.layers[-2].output, name=model.name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T16:54:22.836690Z",
     "end_time": "2023-04-23T16:54:22.968691Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Install MicroAI for C inference code generation (kerascnn2c module)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://bitbucket.org/edge-team-leat/microai_public/get/6adfbcb347d3.zip#subdirectory=third_party/kerascnn2c_fixed\n",
      "  Downloading https://bitbucket.org/edge-team-leat/microai_public/get/6adfbcb347d3.zip (1.9 MB)\n",
      "     ---------------------------------------- 1.9/1.9 MB 4.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\vinh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kerascnn2c==1.0.0) (1.22.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vinh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kerascnn2c==1.0.0) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vinh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->kerascnn2c==1.0.0) (2.1.1)\n",
      "Building wheels for collected packages: kerascnn2c\n",
      "  Building wheel for kerascnn2c (setup.py): started\n",
      "  Building wheel for kerascnn2c (setup.py): finished with status 'done'\n",
      "  Created wheel for kerascnn2c: filename=kerascnn2c-1.0.0-py3-none-any.whl size=21348 sha256=a72fad2a5a6a6c183f5bf47a13180b1d0e52ece833b9fcbebe52d0117e0f24fa\n",
      "  Stored in directory: C:\\Users\\Vinh\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-4rvvczlm\\wheels\\29\\df\\9b\\d62a64e871a29555dc13bc0c189d46297cdf80a3332230aaa1\n",
      "Successfully built kerascnn2c\n",
      "Installing collected packages: kerascnn2c\n",
      "Successfully installed kerascnn2c-1.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\vinh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oundfile (c:\\users\\vinh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install https://bitbucket.org/edge-team-leat/microai_public/get/6adfbcb347d3.zip#subdirectory=third_party/kerascnn2c_fixed\n",
    "import kerascnn2c"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T16:54:25.616055Z",
     "end_time": "2023-04-23T16:54:39.376010Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate C code for the trained model with 16-bit fixed-point representation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\conv1d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...layers\\input_layer\n",
      "......vars\n",
      "...layers\\max_pooling1d\n",
      "......vars\n",
      "...layers\\max_pooling1d_1\n",
      "......vars\n",
      "...layers\\max_pooling1d_2\n",
      "......vars\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-04-23 16:54:45         3844\n",
      "metadata.json                                  2023-04-23 16:54:45           64\n",
      "variables.h5                                   2023-04-23 16:54:45       335984\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-04-23 16:54:44         3844\n",
      "metadata.json                                  2023-04-23 16:54:44           64\n",
      "variables.h5                                   2023-04-23 16:54:44       335984\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\conv1d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...layers\\input_layer\n",
      "......vars\n",
      "...layers\\max_pooling1d\n",
      "......vars\n",
      "...layers\\max_pooling1d_1\n",
      "......vars\n",
      "...layers\\max_pooling1d_2\n",
      "......vars\n",
      "...vars\n",
      "———————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Inputs                           | Layer                            | Outputs                         \n",
      "———————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "                                 | input_28                         | conv1d_81                       \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "input_28                         | conv1d_81                        | max_pooling1d_66                \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "conv1d_81                        | max_pooling1d_66                 | conv1d_82                       \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_66                 | conv1d_82                        | max_pooling1d_67                \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "conv1d_82                        | max_pooling1d_67                 | conv1d_83                       \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_67                 | conv1d_83                        | max_pooling1d_68                \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "conv1d_83                        | max_pooling1d_68                 | flatten_43                      \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_68                 | flatten_43                       | dense_27                        \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "flatten_43                       | dense_27                         |                                 \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "\n",
      "After optimization:\n",
      "———————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Inputs                           | Layer                            | Outputs                         \n",
      "———————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "                                 | input_28                         | conv1d_81                       \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "input_28                         | conv1d_81                        | max_pooling1d_66                \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "conv1d_81                        | max_pooling1d_66                 | conv1d_82                       \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_66                 | conv1d_82                        | max_pooling1d_67                \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "conv1d_82                        | max_pooling1d_67                 | conv1d_83                       \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_67                 | conv1d_83                        | max_pooling1d_68                \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "conv1d_83                        | max_pooling1d_68                 | flatten_43                      \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_68                 | flatten_43                       | dense_27                        \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "flatten_43                       | dense_27                         |                                 \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = kerascnn2c.Converter(output_path=Path('gsc_output_fixed'),\n",
    "                           fixed_point=9, # Number of bits for the fractional part, Q7.9 format\n",
    "                           number_type='int16_t', # Data type for weights/activations (16 bits quantization)\n",
    "                           long_number_type='int32_t', # Data type for intermediate results\n",
    "                           number_min=-(2**15), # Minimum value for 16-bit signed integers\n",
    "                           number_max=(2**15)-1 # Maximum value for 16-bit signed integers\n",
    "                          ).convert_model(copy.deepcopy(model))\n",
    "with open('gsc_model_fixed.h', 'w') as f:\n",
    "    f.write(res)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T16:54:45.717695Z",
     "end_time": "2023-04-23T16:54:47.039538Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compile the 16-bit fixed-point C code for x86 and evaluate on small dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gsc_output_fixed/model.c: In function â€˜void cnn(const number_t (*)[16000], number_t*)â€™:\n",
      "gsc_output_fixed/model.c:114:18: warning: left operand of comma operator has no effect [-Wunused-value]\n",
      "  114 |     activations2.max_pooling1d_68_output,\n",
      "      |     ~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "cc1plus: fatal error: main.cpp: No such file or directory\n",
      "compilation terminated.\n",
      "'.' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex‚cutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "!g++ -Wall -Wextra -pedantic -Ofast -o gsc_fixed -Igsc_output_fixed/ gsc_output_fixed/model.c main.cpp\n",
    "!./gsc_fixed x_test_gsc_250.csv y_test_gsc_250.csv"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T16:54:53.358777Z",
     "end_time": "2023-04-23T16:54:56.140500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
