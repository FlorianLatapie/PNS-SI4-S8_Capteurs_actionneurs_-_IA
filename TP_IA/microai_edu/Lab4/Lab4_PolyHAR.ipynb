{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: PolyHAR CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Conv1D, MaxPool1D, Flatten, Dense, Activation\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load PolyHAR dataset (EllcieHAR format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_full = []\n",
    "y_full = []\n",
    "with open('polyhar.csv') as f:\n",
    "    next(f) # Skip header\n",
    "    for l in f:\n",
    "        d = l.split(';')\n",
    "        x_full.append([float(d[1]), float(d[2]), float(d[3])]) # Store 3-axis accelerometer adata\n",
    "        y_full.append(1 if 'Positive' in d[4] else 0) # Store positive labels\n",
    "\n",
    "x_full = np.array(x_full)\n",
    "y_full = np.array(y_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SIZE = 32\n",
    "CLASSES = 2\n",
    "windowscount = np.ceil(x_full.shape[0]/SIZE).astype(int)\n",
    "x_full = np.resize(x_full, (windowscount, SIZE, x_full.shape[-1]))\n",
    "y_full = np.resize(y_full, (windowscount, SIZE))\n",
    "y_full = np.array([np.bincount(w).argmax() for w in y_full]) # Select label with highest number of occurence for each window\n",
    "y_full = to_categorical(y_full, num_classes=CLASSES) # Convert back to one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RATIO = 0.2 # 20% test, 80% train\n",
    "n = int(len(x_full) * RATIO)\n",
    "\n",
    "# Randomize windows\n",
    "p = np.random.permutation(len(x_full))\n",
    "x_full = x_full[p]\n",
    "y_full = y_full[p]\n",
    "\n",
    "x_test = x_full[-n:]\n",
    "y_test = y_full[-n:]\n",
    "\n",
    "x_train = x_full[:-len(x_test)]\n",
    "y_train = y_full[:-len(y_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export pre-processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.savetxt('x_train_polyhar.csv', x_train.reshape((x_train.shape[0], -1)), delimiter=',', fmt='%s')\n",
    "np.savetxt('y_train_polyhar.csv', y_train, delimiter=',', fmt='%s')\n",
    "np.savetxt('x_test_polyhar.csv', x_test.reshape((x_test.shape[0], -1)), delimiter=',', fmt='%s')\n",
    "np.savetxt('y_test_polyhar.csv', y_test, delimiter=',', fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_1 (Conv1D)           (None, 30, 2)             20        \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 60)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 122       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 142\n",
      "Trainable params: 142\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(SIZE, 3)))\n",
    "model.add(Conv1D(filters=2, kernel_size=3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=CLASSES))\n",
    "model.add(Activation('softmax')) # SoftMax activation needs to be separate from Dense to remove it later on\n",
    "# EXPLORE Learning Rate\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=10e-5)\n",
    "model.summary()\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "8/8 [==============================] - 3s 37ms/step - loss: 0.6760 - categorical_accuracy: 0.8922 - val_loss: 0.6639 - val_categorical_accuracy: 0.8966\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6749 - categorical_accuracy: 0.8836 - val_loss: 0.6624 - val_categorical_accuracy: 0.8966\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6737 - categorical_accuracy: 0.8836 - val_loss: 0.6609 - val_categorical_accuracy: 0.8966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f10e303d360>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=3, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 0.6609 - categorical_accuracy: 0.8966 - 31ms/epoch - 15ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "tf.Tensor(\n",
      "[[41  0]\n",
      " [ 6 11]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=2)\n",
    "pred_test = model.predict(x_test)\n",
    "print(tf.math.confusion_matrix(y_test.argmax(axis=1), pred_test.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('lab4_polyhar.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove SoftMax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Model(model.input, model.layers[-2].output, name=model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install MicroAI for C inference code generation (kerascnn2c module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://bitbucket.org/edge-team-leat/microai_public/get/6adfbcb347d3.zip#subdirectory=third_party/kerascnn2c_fixed\n",
      "  Downloading https://bitbucket.org/edge-team-leat/microai_public/get/6adfbcb347d3.zip (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from kerascnn2c==1.0.0) (1.23.5)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from kerascnn2c==1.0.0) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->kerascnn2c==1.0.0) (2.1.2)\n",
      "Building wheels for collected packages: kerascnn2c\n",
      "  Building wheel for kerascnn2c (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kerascnn2c: filename=kerascnn2c-1.0.0-py3-none-any.whl size=21339 sha256=377551b70414d3e8d6830e664f70555baf5451589adc49a0f63b446459e85e2e\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ydfsihk6/wheels/29/df/9b/d62a64e871a29555dc13bc0c189d46297cdf80a3332230aaa1\n",
      "Successfully built kerascnn2c\n",
      "Installing collected packages: kerascnn2c\n",
      "Successfully installed kerascnn2c-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install https://bitbucket.org/edge-team-leat/microai_public/get/6adfbcb347d3.zip#subdirectory=third_party/kerascnn2c_fixed\n",
    "import kerascnn2c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate C code for the trained model with 16-bit fixed-point representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......input_layer\n",
      ".........vars\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "metadata.json                                  2023-03-31 14:33:13           64\n",
      "config.json                                    2023-03-31 14:33:13         1749\n",
      "variables.h5                                   2023-03-31 14:33:13        13600\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "metadata.json                                  2023-03-31 14:33:12           64\n",
      "config.json                                    2023-03-31 14:33:12         1749\n",
      "variables.h5                                   2023-03-31 14:33:12        13600\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......conv1d\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......input_layer\n",
      ".........vars\n",
      "...vars\n",
      "———————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Inputs                           | Layer                            | Outputs                         \n",
      "———————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "                                 | input_2                          | conv1d_1                        \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "input_2                          | conv1d_1                         | flatten_1                       \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "conv1d_1                         | flatten_1                        | dense_1                         \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "flatten_1                        | dense_1                          |                                 \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "\n",
      "After optimization:\n",
      "———————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Inputs                           | Layer                            | Outputs                         \n",
      "———————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "                                 | input_2                          | conv1d_1                        \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "input_2                          | conv1d_1                         | flatten_1                       \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "conv1d_1                         | flatten_1                        | dense_1                         \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "flatten_1                        | dense_1                          |                                 \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = kerascnn2c.Converter(output_path=Path('polyhar_output_fixed'),\n",
    "                           fixed_point=9, # Number of bits for the fractional part, Q7.9 format\n",
    "                           number_type='int16_t', # Data type for weights/activations (16 bits quantization)\n",
    "                           long_number_type='int32_t', # Data type for intermediate results\n",
    "                           number_min=-(2**15), # Minimum value for 16-bit signed integers\n",
    "                           number_max=(2**15)-1 # Maximum value for 16-bit signed integers\n",
    "                          ).convert_model(copy.deepcopy(model))\n",
    "with open('polyhar_model_fixed.h', 'w') as f:\n",
    "    f.write(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compile the 16-bit fixed-point C code for x86 and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01m\u001b[Kpolyhar_output_fixed/model.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid cnn(const number_t (*)[32], number_t*)\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[Kpolyhar_output_fixed/model.c:55:18:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kleft operand of comma operator has no effect [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-value\u0007-Wunused-value\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "   55 |     \u001b[01;35m\u001b[Kactivations1.conv1d_1_output\u001b[m\u001b[K,\n",
      "      |     \u001b[01;35m\u001b[K~~~~~~~~~~~~~^~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "Testing accuracy: 0.896552\n"
     ]
    }
   ],
   "source": [
    "!g++ -Wall -Wextra -pedantic -Ofast -o polyhar_fixed -Ipolyhar_output_fixed/ polyhar_output_fixed/model.c main.cpp \n",
    "!./polyhar_fixed x_test_polyhar.csv y_test_polyhar.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
