{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 Part I: UCI-HAR CNN with MicroAI deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Conv1D, MaxPool1D, Flatten, Dense, Activation\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and format UCI-HAR dataset (raw data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip\n",
      "60999314/60999314 [==============================] - 198s 3us/step\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'eof'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [2]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[0m dataset_path \u001B[38;5;241m=\u001B[39m \u001B[43mget_file\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mhttps://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI\u001B[39;49m\u001B[38;5;124;43m%\u001B[39;49m\u001B[38;5;124;43m20HAR\u001B[39;49m\u001B[38;5;124;43m%\u001B[39;49m\u001B[38;5;124;43m20Dataset.zip\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextract\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfile_hash\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m53e099237392e0b9602f8c38f578bd8f\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# Download, cache and extract UCI-HAR\u001B[39;00m\n\u001B[0;32m      2\u001B[0m dataset_dir \u001B[38;5;241m=\u001B[39m Path(dataset_path)\u001B[38;5;241m.\u001B[39mparent\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_set\u001B[39m(dataset_dir, part: \u001B[38;5;28mstr\u001B[39m): \u001B[38;5;66;03m# Load separate sensor signals and combine them into a single array, load labels separately\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\data_utils.py:328\u001B[0m, in \u001B[0;36mget_file\u001B[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001B[0m\n\u001B[0;32m    325\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m untar_fpath\n\u001B[0;32m    327\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m extract:\n\u001B[1;32m--> 328\u001B[0m     \u001B[43m_extract_archive\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatadir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marchive_format\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    330\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m fpath\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\data_utils.py:139\u001B[0m, in \u001B[0;36m_extract_archive\u001B[1;34m(file_path, path, archive_format)\u001B[0m\n\u001B[0;32m    136\u001B[0m     open_fn \u001B[38;5;241m=\u001B[39m zipfile\u001B[38;5;241m.\u001B[39mZipFile\n\u001B[0;32m    137\u001B[0m     is_match_fn \u001B[38;5;241m=\u001B[39m zipfile\u001B[38;5;241m.\u001B[39mis_zipfile\n\u001B[1;32m--> 139\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mis_match_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile_path\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m    140\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m open_fn(file_path) \u001B[38;5;28;01mas\u001B[39;00m archive:\n\u001B[0;32m    141\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tarfile.py:2498\u001B[0m, in \u001B[0;36mis_tarfile\u001B[1;34m(name)\u001B[0m\n\u001B[0;32m   2496\u001B[0m     t \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(fileobj\u001B[38;5;241m=\u001B[39mname)\n\u001B[0;32m   2497\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2498\u001B[0m     t \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2499\u001B[0m t\u001B[38;5;241m.\u001B[39mclose()\n\u001B[0;32m   2500\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tarfile.py:1613\u001B[0m, in \u001B[0;36mTarFile.open\u001B[1;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001B[0m\n\u001B[0;32m   1611\u001B[0m     saved_pos \u001B[38;5;241m=\u001B[39m fileobj\u001B[38;5;241m.\u001B[39mtell()\n\u001B[0;32m   1612\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1613\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(name, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m, fileobj, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1614\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ReadError, CompressionError) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1615\u001B[0m     error_msgs\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m- method \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcomptype\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tarfile.py:1742\u001B[0m, in \u001B[0;36mTarFile.xzopen\u001B[1;34m(cls, name, mode, fileobj, preset, **kwargs)\u001B[0m\n\u001B[0;32m   1739\u001B[0m fileobj \u001B[38;5;241m=\u001B[39m LZMAFile(fileobj \u001B[38;5;129;01mor\u001B[39;00m name, mode, preset\u001B[38;5;241m=\u001B[39mpreset)\n\u001B[0;32m   1741\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1742\u001B[0m     t \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mtaropen(name, mode, fileobj, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (LZMAError, \u001B[38;5;167;01mEOFError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1744\u001B[0m     fileobj\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tarfile.py:1663\u001B[0m, in \u001B[0;36mTarFile.taropen\u001B[1;34m(cls, name, mode, fileobj, **kwargs)\u001B[0m\n\u001B[0;32m   1661\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mode \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m   1662\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmode must be \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ma\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m or \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1663\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m(name, mode, fileobj, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tarfile.py:1523\u001B[0m, in \u001B[0;36mTarFile.__init__\u001B[1;34m(self, name, mode, fileobj, format, tarinfo, dereference, ignore_zeros, encoding, errors, pax_headers, debug, errorlevel, copybufsize)\u001B[0m\n\u001B[0;32m   1521\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   1522\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfirstmember \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1523\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfirstmember \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnext\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1525\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   1526\u001B[0m     \u001B[38;5;66;03m# Move to the end of the archive,\u001B[39;00m\n\u001B[0;32m   1527\u001B[0m     \u001B[38;5;66;03m# before the first empty block.\u001B[39;00m\n\u001B[0;32m   1528\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tarfile.py:2358\u001B[0m, in \u001B[0;36mTarFile.next\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   2356\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ReadError(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzlib error: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m   2357\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2358\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[0;32m   2359\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n\u001B[0;32m   2360\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tarfile.py:2331\u001B[0m, in \u001B[0;36mTarFile.next\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   2329\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m   2330\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 2331\u001B[0m         tarinfo \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarinfo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfromtarfile\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2332\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m EOFHeaderError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   2333\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mignore_zeros:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tarfile.py:1113\u001B[0m, in \u001B[0;36mTarInfo.fromtarfile\u001B[1;34m(cls, tarfile)\u001B[0m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[0;32m   1109\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfromtarfile\u001B[39m(\u001B[38;5;28mcls\u001B[39m, tarfile):\n\u001B[0;32m   1110\u001B[0m     \u001B[38;5;124;03m\"\"\"Return the next TarInfo object from TarFile object\u001B[39;00m\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;124;03m       tarfile.\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1113\u001B[0m     buf \u001B[38;5;241m=\u001B[39m \u001B[43mtarfile\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfileobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mBLOCKSIZE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1114\u001B[0m     obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mfrombuf(buf, tarfile\u001B[38;5;241m.\u001B[39mencoding, tarfile\u001B[38;5;241m.\u001B[39merrors)\n\u001B[0;32m   1115\u001B[0m     obj\u001B[38;5;241m.\u001B[39moffset \u001B[38;5;241m=\u001B[39m tarfile\u001B[38;5;241m.\u001B[39mfileobj\u001B[38;5;241m.\u001B[39mtell() \u001B[38;5;241m-\u001B[39m BLOCKSIZE\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\lzma.py:200\u001B[0m, in \u001B[0;36mLZMAFile.read\u001B[1;34m(self, size)\u001B[0m\n\u001B[0;32m    194\u001B[0m \u001B[38;5;124;03m\"\"\"Read up to size uncompressed bytes from the file.\u001B[39;00m\n\u001B[0;32m    195\u001B[0m \n\u001B[0;32m    196\u001B[0m \u001B[38;5;124;03mIf size is negative or omitted, read until EOF is reached.\u001B[39;00m\n\u001B[0;32m    197\u001B[0m \u001B[38;5;124;03mReturns b\"\" if the file is already at EOF.\u001B[39;00m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    199\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_can_read()\n\u001B[1;32m--> 200\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_buffer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43msize\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\_compression.py:68\u001B[0m, in \u001B[0;36mDecompressReader.readinto\u001B[1;34m(self, b)\u001B[0m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mreadinto\u001B[39m(\u001B[38;5;28mself\u001B[39m, b):\n\u001B[0;32m     67\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mmemoryview\u001B[39m(b) \u001B[38;5;28;01mas\u001B[39;00m view, view\u001B[38;5;241m.\u001B[39mcast(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mB\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m byte_view:\n\u001B[1;32m---> 68\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mbyte_view\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     69\u001B[0m         byte_view[:\u001B[38;5;28mlen\u001B[39m(data)] \u001B[38;5;241m=\u001B[39m data\n\u001B[0;32m     70\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(data)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\_compression.py:82\u001B[0m, in \u001B[0;36mDecompressReader.read\u001B[1;34m(self, size)\u001B[0m\n\u001B[0;32m     79\u001B[0m \u001B[38;5;66;03m# Depending on the input data, our call to the decompressor may not\u001B[39;00m\n\u001B[0;32m     80\u001B[0m \u001B[38;5;66;03m# return any data. In this case, try again after reading another block.\u001B[39;00m\n\u001B[0;32m     81\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m---> 82\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_decompressor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meof\u001B[49m:\n\u001B[0;32m     83\u001B[0m         rawblock \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decompressor\u001B[38;5;241m.\u001B[39munused_data \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m     84\u001B[0m                     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39mread(BUFFER_SIZE))\n\u001B[0;32m     85\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m rawblock:\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'eof'"
     ]
    }
   ],
   "source": [
    "dataset_path = get_file(None, \"https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip\", extract=True, file_hash=\"53e099237392e0b9602f8c38f578bd8f\") # Download, cache and extract UCI-HAR\n",
    "dataset_dir = Path(dataset_path).parent\n",
    "\n",
    "def load_set(dataset_dir, part: str): # Load separate sensor signals and combine them into a single array, load labels separately\n",
    "    data = np.hstack([np.loadtxt(dataset_dir/'UCI HAR Dataset'/part/'Inertial Signals'/f'{sensor}_{axis}_{part}.txt')\n",
    "                for sensor in ('body_acc', 'body_gyro', 'total_acc')\n",
    "                    for axis in ('x', 'y', 'z')]).reshape((-1, 128, 9))\n",
    "    labels = to_categorical(np.loadtxt(dataset_dir/'UCI HAR Dataset'/part/f'y_{part}.txt') - 1)\n",
    "    return data, labels\n",
    "\n",
    "x_train, y_train = load_set(dataset_dir, 'train')\n",
    "x_test, y_test = load_set(dataset_dir, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export complete test dataset (2947 vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('x_test_uci-har.csv', x_test.reshape((x_test.shape[0], -1)), delimiter=',', fmt='%s')\n",
    "np.savetxt('y_test_uci-har.csv', y_test, delimiter=',', fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export small dataset (250 vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_250 = x_test[0:250]\n",
    "y_test_250 = y_test[0:250]\n",
    "np.savetxt('x_test_uci-har_250.csv', x_test_250.reshape((x_test_250.shape[0], -1)), delimiter=',', fmt='%s')\n",
    "np.savetxt('y_test_uci-har_250.csv', y_test_250, delimiter=',', fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(128, 9)))\n",
    "model.add(Conv1D(filters=8, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool1D())\n",
    "model.add(Conv1D(filters=8, kernel_size=5, activation='relu'))\n",
    "model.add(MaxPool1D())\n",
    "model.add(Conv1D(filters=8, kernel_size=7, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=6))\n",
    "model.add(Activation('softmax')) # SoftMax activation needs to be separate from Dense to remove it later on\n",
    "# EXPLORE Learning Rate\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=10e-3)\n",
    "model.summary()\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=7, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model on complete test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test, verbose=2)\n",
    "pred_test = model.predict(x_test)\n",
    "print(tf.math.confusion_matrix(y_test.argmax(axis=1), pred_test.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model on small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test_250, y_test_250, verbose=2)\n",
    "pred_test_250 = model.predict(x_test_250)\n",
    "print(tf.math.confusion_matrix(y_test_250.argmax(axis=1), pred_test_250.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('lab3_part1_uci-har_microai.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove SoftMax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(model.input, model.layers[-2].output, name=model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install MicroAI for C inference code generation (kerascnn2c module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install https://bitbucket.org/edge-team-leat/microai_public/get/6adfbcb347d3.zip#subdirectory=third_party/kerascnn2c_fixed\n",
    "import kerascnn2c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate C code for the trained model with 32-bit floating-point representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = kerascnn2c.Converter(output_path=Path('uci-har_output_floating'),\n",
    "                           fixed_point=0, # floating-point\n",
    "                           number_type='float', # Data type for weights/activations (single-precision floating-point)\n",
    "                           long_number_type='float', # Data type for intermediate results\n",
    "                           number_min=-float('inf'), # Minimum value for float is negative infinity\n",
    "                           number_max=float('inf') # Maximum value for float is infinity\n",
    "                          ).convert_model(copy.deepcopy(model))\n",
    "with open('uci-har_model_floating.h', 'w') as f:\n",
    "    f.write(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compile the 32-bit floating-point C code for x86 and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!g++ -Wall -Wextra -pedantic -Ofast -o uci-har_floating -Iuci-har_output_floating/ uci-har_output_floating/model.c main.cpp \n",
    "!./uci-har_floating x_test_uci-har.csv y_test_uci-har.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate C code for the trained model with 16-bit fixed-point representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = kerascnn2c.Converter(output_path=Path('uci-har_output_fixed'),\n",
    "                           fixed_point=9, # Number of bits for the fractional part, Q7.9 format\n",
    "                           number_type='int16_t', # Data type for weights/activations (16 bits quantization)\n",
    "                           long_number_type='int32_t', # Data type for intermediate results\n",
    "                           number_min=-(2**15), # Minimum value for 16-bit signed integers\n",
    "                           number_max=(2**15)-1 # Maximum value for 16-bit signed integers\n",
    "                          ).convert_model(copy.deepcopy(model))\n",
    "with open('uci-har_model_fixed.h', 'w') as f:\n",
    "    f.write(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compile the 16-bit fixed-point C code for x86 and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!g++ -Wall -Wextra -pedantic -Ofast -o uci-har_fixed -Iuci-har_output_fixed/ uci-har_output_fixed/model.c main.cpp \n",
    "!./uci-har_fixed x_test_uci-har.csv y_test_uci-har.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
